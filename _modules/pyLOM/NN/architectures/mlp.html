
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>pyLOM.NN.architectures.mlp &#8212; pyLOM  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/custom.css?v=de90da8b" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/pyLOM/NN/architectures/mlp';</script>
    <link rel="icon" href="../../../../_static/favicon_tmp.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="2.1.0" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/logo_tmp.webp" class="logo__image only-light" alt="pyLOM"/>
    <img src="../../../../_static/logo_tmp.webp" class="logo__image only-dark pst-js-only" alt="pyLOM"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../api/modules.html">
    API reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../install.html">
    Installation
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ArnauMiro/pyLowOrder" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../api/modules.html">
    API reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../examples.html">
    Examples
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../install.html">
    Installation
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/ArnauMiro/pyLowOrder" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../index.html" class="nav-link">Module code</a></li>
    
    
    <li class="breadcrumb-item"><a href="../../NN.html" class="nav-link">pyLOM.NN</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">pyLOM.NN.architectures.mlp</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for pyLOM.NN.architectures.mlp</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">from</span> <span class="nn">..optimizer</span> <span class="kn">import</span> <span class="n">OptunaOptimizer</span><span class="p">,</span> <span class="n">TrialPruned</span>
<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">set_seed</span>  <span class="c1"># pyLOM/NN/__init__.py</span>
<span class="kn">from</span> <span class="nn">...</span> <span class="kn">import</span> <span class="n">pprint</span><span class="p">,</span> <span class="n">cr</span>  <span class="c1"># pyLOM/__init__.py</span>
<span class="kn">from</span> <span class="nn">...utils.errors</span> <span class="kn">import</span> <span class="n">raiseWarning</span>


<div class="viewcode-block" id="MLP">
<a class="viewcode-back" href="../../../../api/pyLOM.NN.html#pyLOM.NN.MLP">[docs]</a>
<span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multi-layer perceptron model for regression tasks. The model is based on the PyTorch library `torch.nn` </span>
<span class="sd">    (detailed documentation can be found at https://pytorch.org/docs/stable/nn.html).</span>

<span class="sd">    Args:</span>
<span class="sd">        input_size (int): Number of input features.</span>
<span class="sd">        output_size (int): Number of output features.</span>
<span class="sd">        n_layers (int): Number of hidden layers.</span>
<span class="sd">        hidden_size (int): Number of neurons in each hidden layer.</span>
<span class="sd">        p_dropouts (float, optional): Dropout probability for the hidden layers (default: ``0.0``).</span>
<span class="sd">        checkpoint_file (str, optional): Path to a checkpoint file to load the model from (default: ``None``).</span>
<span class="sd">        activation (torch.nn.Module, optional): Activation function to use (default: ``torch.nn.functional.relu``).</span>
<span class="sd">        device (torch.device, optional): Device to use (default: ``torch.device(&quot;cpu&quot;)``).</span>
<span class="sd">        seed (int, optional): Seed for reproducibility (default: ``None``).</span>
<span class="sd">        kwargs: Additional keyword arguments.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">output_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">p_dropouts</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">DEVICE</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span> <span class="o">=</span> <span class="n">n_layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_dropouts</span> <span class="o">=</span> <span class="n">p_dropouts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="n">in_size</span> <span class="o">=</span> <span class="n">input_size</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">hidden_size</span>
            <span class="n">out_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_size</span><span class="p">,</span> <span class="n">out_size</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">p_dropouts</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p_dropouts</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">oupt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span> <span class="c1"># Initialize only non-dropout linear layers</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">oupt</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">oupt</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    
<div class="viewcode-block" id="MLP.forward">
<a class="viewcode-back" href="../../../../api/pyLOM.NN.html#pyLOM.NN.MLP.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">z</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">oupt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span></div>

    
<div class="viewcode-block" id="MLP.fit">
<a class="viewcode-back" href="../../../../api/pyLOM.NN.html#pyLOM.NN.MLP.fit">[docs]</a>
    <span class="nd">@cr</span><span class="p">(</span><span class="s1">&#39;MLP.fit&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>
        <span class="n">lr_gamma</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">lr_scheduler_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(),</span>
        <span class="n">optimizer_class</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
        <span class="n">scheduler_class</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LRScheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">,</span>
        <span class="n">print_rate_batch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">print_rate_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span><span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit the model to the training data. If eval_set is provided, the model will be evaluated on this set after each epoch. </span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            train_dataset (torch.utils.data.Dataset): Training dataset to fit the model.</span>
<span class="sd">            eval_dataset (torch.utils.data.Dataset): Evaluation dataset to evaluate the model after each epoch (default: ``None``).</span>
<span class="sd">            epochs (int, optional): Number of epochs to train the model (default: ``100``).</span>
<span class="sd">            lr (float, optional): Learning rate for the optimizer (default: ``0.001``).</span>
<span class="sd">            lr_gamma (float, optional): Multiplicative factor of learning rate decay (default: ``1``).</span>
<span class="sd">            lr_scheduler_step (int, optional): Number of epochs to decay the learning rate (default: ``1``).</span>
<span class="sd">            loss_fn (torch.nn.Module, optional): Loss function to optimize (default: ``torch.nn.MSELoss()``).</span>
<span class="sd">            optimizer_class (torch.optim.Optimizer, optional): Optimizer class to use (default: ``torch.optim.Adam``).</span>
<span class="sd">            scheduler_class (torch.optim.lr_scheduler._LRScheduler, optional): Learning rate scheduler class to use. If ``None``, no scheduler will be used (default: ``torch.optim.lr_scheduler.StepLR``).</span>
<span class="sd">            print_rate_batch (int, optional): Print loss every ``print_rate_batch`` batches (default: ``1``). If set to ``0``, no print will be done.</span>
<span class="sd">            print_rate_epoch (int, optional): Print loss every ``print_rate_epoch`` epochs (default: ``1``). If set to ``0``, no print will be done.</span>
<span class="sd">            kwargs (dict, optional): Additional keyword arguments to pass to the DataLoader. Can be used to set the parameters of the DataLoader (see PyTorch documentation at https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader):</span>
<span class="sd">                </span>
<span class="sd">                - batch_size (int, optional): Batch size (default: ``32``).</span>
<span class="sd">                - shuffle (bool, optional): Shuffle the data (default: ``True``).</span>
<span class="sd">                - num_workers (int, optional): Number of workers to use (default: ``0``).</span>
<span class="sd">                - pin_memory (bool, optional): Pin memory (default: ``True``).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dict[str, List[float]]: Dictionary containing the training and evaluation losses.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataloader_params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
            <span class="s2">&quot;shuffle&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;train_dataloader&quot;</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">dataloader_params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                    <span class="n">dataloader_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">dataloader_params</span><span class="p">)</span>
        
        <span class="n">eval_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">dataloader_params</span><span class="p">)</span> <span class="k">if</span> <span class="n">eval_dataset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span> 

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;optimizer&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer_class</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;scheduler&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">scheduler_class</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="n">lr_scheduler_step</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="n">lr_gamma</span><span class="p">)</span> <span class="k">if</span> <span class="n">scheduler_class</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;checkpoint&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">lr_gamma</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step_size</span> <span class="o">=</span> <span class="n">lr_scheduler_step</span>
            <span class="n">epoch_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">train_loss_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">][</span><span class="mi">3</span><span class="p">]</span>
            <span class="n">test_loss_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;state&quot;</span><span class="p">][</span><span class="mi">4</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">epoch_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">train_loss_list</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">test_loss_list</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">total_epochs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">epoch_list</span><span class="p">)</span><span class="o">+</span><span class="n">epochs</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">epoch_list</span><span class="p">),</span> <span class="mi">1</span><span class="o">+</span><span class="n">total_epochs</span><span class="p">):</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">b_idx</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">):</span>
                <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">oupt</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
                <span class="n">loss_val</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">oupt</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
                <span class="n">loss_val</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">loss_val_item</span> <span class="o">=</span> <span class="n">loss_val</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">train_loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_val_item</span><span class="p">)</span>
                <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss_val_item</span>
                <span class="k">if</span> <span class="n">print_rate_batch</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">b_idx</span> <span class="o">%</span> <span class="n">print_rate_batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">pprint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Batch </span><span class="si">%4d</span><span class="s2">/</span><span class="si">%4d</span><span class="s2"> | Train loss (x1e5) </span><span class="si">%0.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">b_idx</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span> <span class="n">loss_val_item</span> <span class="o">*</span> <span class="mf">1e5</span><span class="p">),</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                   
            <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="p">(</span><span class="n">b_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="n">test_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">if</span> <span class="n">eval_dataloader</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="k">for</span> <span class="n">n_idx</span><span class="p">,</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">eval_dataloader</span><span class="p">):</span>
                        <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">sample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                        <span class="n">test_output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
                        <span class="n">loss_val</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">test_output</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
                        <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss_val</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                <span class="n">test_loss</span> <span class="o">=</span> <span class="n">test_loss</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">test_loss_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">print_rate_epoch</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">%</span> <span class="n">print_rate_epoch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">test_log</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot; | Test loss (x1e5) </span><span class="si">{</span><span class="n">test_loss</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1e5</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">eval_dataloader</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
                <span class="n">pprint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">total_epochs</span><span class="si">}</span><span class="s2"> | Train loss (x1e5) </span><span class="si">{</span><span class="n">train_loss</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mf">1e5</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">test_log</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">epoch_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">{},</span>
                <span class="n">epoch_list</span><span class="p">,</span>
                <span class="n">train_loss_list</span><span class="p">,</span>
                <span class="n">test_loss_list</span><span class="p">,</span>
                <span class="p">)</span>
            
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="n">train_loss_list</span><span class="p">,</span> <span class="s2">&quot;test_loss&quot;</span><span class="p">:</span> <span class="n">test_loss_list</span><span class="p">}</span></div>

    
<div class="viewcode-block" id="MLP.predict">
<a class="viewcode-back" href="../../../../api/pyLOM.NN.html#pyLOM.NN.MLP.predict">[docs]</a>
    <span class="nd">@cr</span><span class="p">(</span><span class="s1">&#39;MLP.predict&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> 
        <span class="n">return_targets</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict the target values for the input data. The dataset is loaded to a DataLoader with the provided keyword arguments. </span>
<span class="sd">        The model is set to evaluation mode and the predictions are made using the input data. </span>
<span class="sd">        To make a prediction from a torch tensor, use the `__call__` method directly.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (torch.utils.data.Dataset): The dataset whose target values are to be predicted using the input data.</span>
<span class="sd">            rescale_output (bool): Whether to rescale the output with the scaler of the dataset (default: ``True``).</span>
<span class="sd">            kwargs (dict, optional): Additional keyword arguments to pass to the DataLoader. Can be used to set the parameters of the DataLoader (see PyTorch documentation at https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader):</span>
<span class="sd">                </span>
<span class="sd">                - batch_size (int, optional): Batch size (default: ``256``).</span>
<span class="sd">                - shuffle (bool, optional): Shuffle the data (default: ``False``).</span>
<span class="sd">                - num_workers (int, optional): Number of workers to use (default: ``0``).</span>
<span class="sd">                - pin_memory (bool, optional): Pin memory (default: ``True``).</span>
<span class="sd"> </span>
<span class="sd">        Returns:</span>
<span class="sd">            Tuple [np.ndarray, np.ndarray]: The predictions and the true target values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dataloader_params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
            <span class="s2">&quot;shuffle&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
            <span class="s2">&quot;num_workers&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;pin_memory&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="p">}</span>
        
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">dataloader_params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">dataloader_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>

        <span class="n">predict_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">dataloader_params</span><span class="p">)</span>

        <span class="n">total_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">predict_dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
        <span class="n">num_columns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span>
        <span class="n">all_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">total_rows</span><span class="p">,</span> <span class="n">num_columns</span><span class="p">))</span>
        <span class="n">all_targets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">total_rows</span><span class="p">,</span> <span class="n">num_columns</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">start_idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">predict_dataloader</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">end_idx</span> <span class="o">=</span> <span class="n">start_idx</span> <span class="o">+</span> <span class="n">batch_size</span>
                <span class="n">all_predictions</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">return_targets</span><span class="p">:</span>
                    <span class="n">all_targets</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">start_idx</span> <span class="o">=</span> <span class="n">end_idx</span>

        <span class="k">if</span> <span class="n">return_targets</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">all_predictions</span><span class="p">,</span> <span class="n">all_targets</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">all_predictions</span></div>


<div class="viewcode-block" id="MLP.save">
<a class="viewcode-back" href="../../../../api/pyLOM.NN.html#pyLOM.NN.MLP.save">[docs]</a>
    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the model to a checkpoint file.</span>

<span class="sd">        Args:</span>
<span class="sd">            path (str): Path to save the model. It can be either a path to a directory or a file name. </span>
<span class="sd">            If it is a directory, the model will be saved with a filename that includes the number of epochs trained.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;input_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span><span class="p">,</span>
            <span class="s2">&quot;output_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">,</span>
            <span class="s2">&quot;n_layers&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="s2">&quot;p_dropouts&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_dropouts</span><span class="p">,</span>
            <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
            <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="s2">&quot;state_dict&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
            <span class="s2">&quot;state&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
        <span class="p">}</span>
        
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;/trained_model_</span><span class="si">{:06d}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span> <span class="o">+</span> <span class="s2">&quot;.pth&quot;</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">path</span> <span class="o">+</span> <span class="n">filename</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="MLP.load">
<a class="viewcode-back" href="../../../../api/pyLOM.NN.html#pyLOM.NN.MLP.load">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> 
        <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">DEVICE</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load the model from a checkpoint file. Does not require the model to be instantiated.</span>

<span class="sd">        Args:</span>
<span class="sd">            path (str): Path to the file to load the model from.</span>
<span class="sd">            device (torch.device, optional): Device to use (default: ``torch.device(&quot;cpu&quot;)``).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Model (MLP): The loaded model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">raiseWarning</span><span class="p">(</span><span class="s2">&quot;The model has been loaded with weights_only set to False. According with torch documentation, this is not recommended if you do not trust the source of your saved model, as it could lead to arbitrary code execution.&quot;</span><span class="p">)</span>
        <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;device&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">device</span>
        <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;input_size&quot;</span><span class="p">],</span>
            <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;output_size&quot;</span><span class="p">],</span>
            <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">],</span>
            <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span>
            <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;p_dropouts&quot;</span><span class="p">],</span>
            <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
            <span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;device&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;state_dict&quot;</span><span class="p">])</span>
        <span class="n">model</span><span class="o">.</span><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">checkpoint</span>
        <span class="k">return</span> <span class="n">model</span></div>

    
<div class="viewcode-block" id="MLP.create_optimized_model">
<a class="viewcode-back" href="../../../../api/pyLOM.NN.html#pyLOM.NN.MLP.create_optimized_model">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="nd">@cr</span><span class="p">(</span><span class="s1">&#39;MLP.create_optimized_model&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">create_optimized_model</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> 
        <span class="n">train_dataset</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> 
        <span class="n">eval_dataset</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> 
        <span class="n">optuna_optimizer</span><span class="p">:</span> <span class="n">OptunaOptimizer</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create an optimized model using Optuna. The model is trained on the training dataset and evaluated on the validation dataset.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            train_dataset (torch.utils.data.Dataset): The training dataset.</span>
<span class="sd">            eval_dataset (torch.utils.data.Dataset): The evaluation dataset.</span>
<span class="sd">            optuna_optimizer (OptunaOptimizer): The optimizer to use for optimization.</span>
<span class="sd">            kwargs: Additional keyword arguments.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple [MLP, Dict]: The optimized model and the optimization parameters.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; from pyLOM.NN import MLP, OptunaOptimizer</span>
<span class="sd">            &gt;&gt;&gt; # Split the dataset</span>
<span class="sd">            &gt;&gt;&gt; train_dataset, eval_dataset = dataset.get_splits([0.8, 0.2])</span>
<span class="sd">            &gt;&gt;&gt; </span>
<span class="sd">            &gt;&gt;&gt; # Define the optimization parameters</span>
<span class="sd">            &gt;&gt;&gt; optimization_params = {</span>
<span class="sd">            &gt;&gt;&gt;     &quot;lr&quot;: (0.00001, 0.01), # optimizable parameter</span>
<span class="sd">            &gt;&gt;&gt;     &quot;epochs&quot;: 50, # fixed parameter</span>
<span class="sd">            &gt;&gt;&gt;     &quot;n_layers&quot;: (1, 4),</span>
<span class="sd">            &gt;&gt;&gt;     &quot;batch_size&quot;: (128, 512),</span>
<span class="sd">            &gt;&gt;&gt;     &quot;hidden_size&quot;: (200, 400),</span>
<span class="sd">            &gt;&gt;&gt;     &quot;p_dropouts&quot;: (0.1, 0.5),</span>
<span class="sd">            &gt;&gt;&gt;     &quot;num_workers&quot;: 0,</span>
<span class="sd">            &gt;&gt;&gt;     &#39;print_rate_epoch&#39;: 5</span>
<span class="sd">            &gt;&gt;&gt; }</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Define the optimizer</span>
<span class="sd">            &gt;&gt;&gt; optimizer = OptunaOptimizer(</span>
<span class="sd">            &gt;&gt;&gt;     optimization_params=optimization_params,</span>
<span class="sd">            &gt;&gt;&gt;     n_trials=5,</span>
<span class="sd">            &gt;&gt;&gt;     direction=&quot;minimize&quot;,</span>
<span class="sd">            &gt;&gt;&gt;     pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5, interval_steps=1),</span>
<span class="sd">            &gt;&gt;&gt;     save_dir=None,</span>
<span class="sd">            &gt;&gt;&gt; )</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create the optimized model</span>
<span class="sd">            &gt;&gt;&gt; model, optimization_params = MLP.create_optimized_model(train_dataset, eval_dataset, optimizer)</span>
<span class="sd">            &gt;&gt;&gt; </span>
<span class="sd">            &gt;&gt;&gt; # Fit the model</span>
<span class="sd">            &gt;&gt;&gt; model.fit(train_dataset, eval_dataset, **optimization_params)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">optimization_params</span> <span class="o">=</span> <span class="n">optuna_optimizer</span><span class="o">.</span><span class="n">optimization_params</span>
        <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_dataset</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">def</span> <span class="nf">optimization_function</span><span class="p">(</span><span class="n">trial</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
            <span class="n">training_params</span> <span class="o">=</span> <span class="p">{}</span>       
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">optimization_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">training_params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_get_optimizing_value</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>
            <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="o">**</span><span class="n">training_params</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">optuna_optimizer</span><span class="o">.</span><span class="n">pruner</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">epochs</span> <span class="o">=</span> <span class="n">training_params</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">]</span>
                <span class="n">training_params</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
                <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">training_params</span><span class="p">)</span>
                    <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">return_targets</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">loss_val</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                    <span class="n">trial</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">loss_val</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">trial</span><span class="o">.</span><span class="n">should_prune</span><span class="p">():</span> 
                        <span class="k">raise</span> <span class="n">TrialPruned</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="o">**</span><span class="n">training_params</span><span class="p">)</span>
                <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">eval_dataset</span><span class="p">,</span> <span class="n">return_targets</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">loss_val</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
            
            <span class="k">return</span> <span class="n">loss_val</span>
        
        <span class="n">best_params</span> <span class="o">=</span> <span class="n">optuna_optimizer</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective_function</span><span class="o">=</span><span class="n">optimization_function</span><span class="p">)</span>

        <span class="c1"># Update params with best ones</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">best_params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">optimization_params</span><span class="p">:</span>
                <span class="n">optimization_params</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_params</span><span class="p">[</span><span class="n">param</span><span class="p">]</span>
        
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="o">**</span><span class="n">optimization_params</span><span class="p">),</span> <span class="n">optimization_params</span></div>


    <span class="k">def</span> <span class="nf">_get_optimizing_value</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">trial</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">use_log</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">1000</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">log</span><span class="o">=</span><span class="n">use_log</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">float</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">value</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">log</span><span class="o">=</span><span class="n">use_log</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span></div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2023-2025.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>