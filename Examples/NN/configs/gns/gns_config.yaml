# config.yaml â€” Experiment configuration file for pyLOM

execution:
  mode: train                        # train | optuna
  resume: false                     # resume from last checkpoint
  basedir: "./data"                 # base directory for input files
  resudir: "./results/exp_01"       # where to save outputs

experiment:
  name: gns_nlr7301_baseline
  description: "Baseline GNS model on NLR7301 airfoil data"
  version: 1.0
  seed: 123
  device: cuda                      # 'cpu', 'cuda', 'cuda:0', etc.
  tags: [GNS, airfoil, baseline]

datasets:
  train_ds: "train_data.h5"
  val_ds: "val_data.h5"
  test_ds: "test_data.h5"

model:
  graph_path: "mesh_graph.h5"
  input_dim: 2
  output_dim: 1
  latent_dim: 16
  hidden_size: 256
  num_msg_passing_layers: 3
  encoder_hidden_layers: 2
  decoder_hidden_layers: 1
  message_hidden_layers: 2
  update_hidden_layers: 2
  activation: ELU
  p_dropouts: 0.1

training:
  epochs: 500
  lr: 5e-4
  lr_gamma: 0.98
  lr_scheduler_step: 1
  optimizer: Adam
  scheduler: StepLR
  loss_fn: MSELoss
  batch_size: 16
  node_batch_size: 512
  num_workers: 4
  pin_memory: true
  verbose: 25

optuna:
  graph_path: "mesh_graph.h5"
  study:
    study_name: gns_optuna_study
    direction: minimize
    timeout: 3600
    n_trials: 50
  search_space:
    model:
      latent_dim: [8, 64]
      hidden_size: [64, 512]
      ...
    training:
      lr: [1e-5, 1e-2]
      batch_size: [4, 64]

evaluation:
  plot_true_vs_pred: true
  plot_train_test_loss: true
  save_model: true
  save_metrics: true

logging:
  level: INFO
  logfile: null
